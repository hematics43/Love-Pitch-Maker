<!DOCTYPE html>
<html>
<head>
  <title>Love Pitch Detector</title>
  <style>
    body {
      background: linear-gradient(to bottom right, #ffc6e5, #ffe8f0);
      color: #c92c6d;
      font-family: 'Comic Sans MS', cursive, sans-serif;
      text-align: center;
      padding: 40px;
    }

    h1 {
      font-size: 2.5em;
      margin-bottom: 10px;
    }

    #freq {
      font-size: 2em;
      margin-top: 10px;
      color: #ff2d6f;
      font-weight: bold;
    }

    canvas {
      border: 2px solid #ff69b4;
      border-radius: 15px;
      box-shadow: 0 0 15px #ff8dc7;
      background-color: #fff0f6;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <h1>💕 Love Pitch Detector 💕</h1>
  <p>You're speaking in a frequency of love!</p>
  <div id="freq">Waiting for love...</div>
  <canvas id="visualizer" width="600" height="200"></canvas>

  <script>
    async function startAudio() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const bufferLength = analyser.fftSize;
      const data = new Float32Array(bufferLength);

      source.connect(analyser);

      const canvas = document.getElementById("visualizer");
      const ctx = canvas.getContext("2d");

      function drawWaveform() {
        analyser.getFloatTimeDomainData(data);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.beginPath();
        ctx.strokeStyle = "#ff2d6f";
        ctx.lineWidth = 3;

        const sliceWidth = canvas.width / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = data[i] * 0.5 + 0.5;
          const y = v * canvas.height;
          if (i === 0) ctx.moveTo(x, y);
          else ctx.lineTo(x, y);
          x += sliceWidth;
        }
        ctx.stroke();
        requestAnimationFrame(drawWaveform);
      }

      function autoCorrelate(buffer, sampleRate) {
        let SIZE = buffer.length;
        let MAX_SAMPLES = Math.floor(SIZE / 2);
        let bestOffset = -1;
        let bestCorrelation = 0;
        let rms = 0;

        for (let i = 0; i < SIZE; i++) {
          const val = buffer[i];
          rms += val * val;
        }
        rms = Math.sqrt(rms / SIZE);
        if (rms < 0.01) return -1;

        let lastCorrelation = 1;
        for (let offset = 0; offset < MAX_SAMPLES; offset++) {
          let correlation = 0;
          for (let i = 0; i < MAX_SAMPLES; i++) {
            correlation += Math.abs((buffer[i]) - (buffer[i + offset]));
          }
          correlation = 1 - (correlation / MAX_SAMPLES);
          if (correlation > 0.9 && correlation > lastCorrelation) {
            bestCorrelation = correlation;
            bestOffset = offset;
          }
          lastCorrelation = correlation;
        }

        if (bestCorrelation > 0.01) {
          return sampleRate / bestOffset;
        }
        return -1;
      }

      function updateFreq() {
        analyser.getFloatTimeDomainData(data);
        const freq = autoCorrelate(data, audioCtx.sampleRate);
        document.getElementById("freq").textContent =
          freq !== -1 ? `❤️ ${freq.toFixed(2)} Hz` : "Waiting for love...";
        requestAnimationFrame(updateFreq);
      }

      drawWaveform();
      updateFreq();
    }

    startAudio().catch(err => {
      alert("Microphone access denied or not supported.");
    });
  </script>
</body>
</html>
